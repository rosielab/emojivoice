{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Model already present at /home/paige/.local/share/matcha_tts/hifigan_univ_v1!\n",
      "Removing weight norm...\n",
      "Once upon a time, in the vast Digital Kingdom, there lived a brave Pixel Prince üòé.\n",
      "His realm was made of glowing grids and circuits, where everything was in perfect order.\n",
      "Until one day, a fearsome Glitch Dragon appeared, corrupting the code and causing chaos üò°.\n",
      "The Prince looked up at the flickering skies, worried ü§î.\n",
      "This dragon is messing with our realm's code! I must defeat it üò°!\n",
      "With his loyal companion, Circuit the Byte Fairy, by his side, the Prince set off on a quest üòç.\n",
      "As they traveled through binary forests and across streaming rivers, Circuit kept spirits high üòç.\n",
      "Making the Prince laugh with her digital jokes ü§£.\n",
      "Finally, they arrived at Glitch Mountain, where the dragon lurked.\n",
      "The sight of the massive, glitching creature made the Prince gasp üòÆ.\n",
      "The dragon roared, sending corrupted data flying, freezing parts of the world.\n",
      "Circuit sighed.\n",
      "Dragons‚Ä¶ always so dramatic üôÑ.\n",
      "The Pixel Prince chuckled nervously, but he knew the battle had to be fought üòÖ.\n",
      "He gripped his enchanted firewall sword, faced the dragon, and after a fierce clash, he struck the final blow, locking the dragon in a patch of clean code üòÅ.\n",
      "The Digital Kingdom was restored, and everyone celebrated, feeling peace and joy.\n",
      "But deep in the shadows of Glitch Mountain, the dragon shed a pixelated tear, longing for a world where it, too, could live in harmonyüò≠.\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import soundfile as sf\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "\n",
    "from matcha.hifigan.config import v1\n",
    "from matcha.hifigan.denoiser import Denoiser\n",
    "from matcha.hifigan.env import AttrDict\n",
    "from matcha.hifigan.models import Generator as HiFiGAN\n",
    "from matcha.models.matcha_tts import MatchaTTS\n",
    "from matcha.text import sequence_to_text, text_to_sequence\n",
    "from matcha.utils.utils import get_user_data_dir, intersperse, assert_model_downloaded\n",
    "\n",
    "import emoji\n",
    "\n",
    "VOICE = 'emoji'\n",
    "SCRIPT_PATH = \"fairytale_script.txt\"\n",
    "WAV_PATH = \"outputs\"\n",
    "############################ TTS PARAMETERS ############################################################################\n",
    "if VOICE == 'base' :\n",
    "    TTS_MODEL_PATH = \"../../Matcha-TTS/models/matcha_vctk.ckpt\"\n",
    "    SPEAKING_RATE = 0.8\n",
    "    STEPS = 10\n",
    "    LANGUAGE = \"en\"\n",
    "else:\n",
    "    TTS_MODEL_PATH = \"../../Matcha-TTS/models/emoji-hri-paige-inference.ckpt\"\n",
    "    SPEAKING_RATE = 0.8\n",
    "    STEPS = 10\n",
    "    LANGUAGE = \"en\"\n",
    "# hifigan_univ_v1 is suggested, unless the custom model is trained on LJ Speech\n",
    "VOCODER_NAME= \"hifigan_univ_v1\"\n",
    "TTS_TEMPERATURE = 0.667\n",
    "VOCODER_URLS = {\n",
    "    \"hifigan_T2_v1\": \"https://github.com/shivammehta25/Matcha-TTS-checkpoints/releases/download/v1.0/generator_v1\",  # Old url: https://drive.google.com/file/d/14NENd4equCBLyyCSke114Mv6YR_j_uFs/view?usp=drive_link\n",
    "    \"hifigan_univ_v1\": \"https://github.com/shivammehta25/Matcha-TTS-checkpoints/releases/download/v1.0/g_02500000\",  # Old url: https://drive.google.com/file/d/1qpgI41wNXFcH-iKq1Y42JlBC9j0je8PW/view?usp=drive_link\n",
    "}\n",
    "\n",
    "#maps the emojis used by the LLM to the speaker numbers from the Matcha-TTS checkpoint\n",
    "emoji_mapping = {\n",
    "    'üòç' : 107,\n",
    "    'üò°' : 58,\n",
    "    'üòé' : 79,\n",
    "    'üò≠' : 103,\n",
    "    'üôÑ' : 66,\n",
    "    'üòÅ' : 18,\n",
    "    'üôÇ' : 12,\n",
    "    'ü§£' : 15,\n",
    "    'üòÆ' : 54,\n",
    "    'üòÖ' : 22,\n",
    "    'ü§î' : 17\n",
    "}\n",
    "\n",
    "#male voice mapping\n",
    "#emoji_mapping = {\n",
    "#    'üòç' : 4,\n",
    "#    'üò°' : 5,\n",
    "#    'üòé' : 6,\n",
    "#    'üò≠' : 13,\n",
    "#    'üôÑ' : 16,\n",
    "#    'üòÅ' : 26,\n",
    "#    'üôÇ' : 30,\n",
    "#    'ü§£' : 38,\n",
    "#    'üòÆ' : 60,\n",
    "#    'üòÖ' : 82,\n",
    "#    'ü§î' : 97\n",
    "#}\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "def process_text(text: str, device: torch.device, language: str):\n",
    "    cleaners = {\n",
    "        \"en\": \"english_cleaners2\",\n",
    "        \"fr\": \"french_cleaners\",\n",
    "        \"ja\": \"japanese_cleaners\",\n",
    "        \"es\": \"spanish_cleaners\",\n",
    "        \"de\": \"german_cleaners\",\n",
    "    }\n",
    "    if language not in cleaners:\n",
    "        print(\"Invalid language. Current supported languages: en (English), fr (French), ja (Japanese), de (German).\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    x = torch.tensor(\n",
    "        intersperse(text_to_sequence(text, [cleaners[language]])[0], 0),\n",
    "        dtype=torch.long,\n",
    "        device=device,\n",
    "    )[None]\n",
    "    x_lengths = torch.tensor([x.shape[-1]], dtype=torch.long, device=device)\n",
    "    x_phones = sequence_to_text(x.squeeze(0).tolist())\n",
    "\n",
    "    return {\"x_orig\": text, \"x\": x, \"x_lengths\": x_lengths, \"x_phones\": x_phones}\n",
    "\n",
    "def load_matcha(checkpoint_path, device):\n",
    "    model = MatchaTTS.load_from_checkpoint(checkpoint_path, map_location=device)\n",
    "    _ = model.eval()\n",
    "    return model\n",
    "\n",
    "def load_hifigan(checkpoint_path, device):\n",
    "    h = AttrDict(v1)\n",
    "    hifigan = HiFiGAN(h).to(device)\n",
    "    hifigan.load_state_dict(torch.load(checkpoint_path, map_location=device)[\"generator\"])\n",
    "    _ = hifigan.eval()\n",
    "    hifigan.remove_weight_norm()\n",
    "    return hifigan\n",
    "\n",
    "def load_vocoder(vocoder_name, checkpoint_path, device):\n",
    "    vocoder = None\n",
    "    if vocoder_name in (\"hifigan_T2_v1\", \"hifigan_univ_v1\"):\n",
    "        vocoder = load_hifigan(checkpoint_path, device)\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            f\"Vocoder not implemented! define a load_<<vocoder_name>> method for it\"\n",
    "        )\n",
    "\n",
    "    denoiser = Denoiser(vocoder, mode=\"zeros\")\n",
    "    return vocoder, denoiser\n",
    "\n",
    "@torch.inference_mode()\n",
    "def to_waveform(mel, vocoder, denoiser=None):\n",
    "    audio = vocoder(mel).clamp(-1, 1)\n",
    "    if denoiser is not None:\n",
    "        audio = denoiser(audio.squeeze(), strength=0.00025).cpu().squeeze()\n",
    "\n",
    "    return audio.cpu().squeeze()\n",
    "\n",
    "def save_to_folder(filename: str, output: dict, folder: str):\n",
    "    folder = Path(folder)\n",
    "    folder.mkdir(exist_ok=True, parents=True)\n",
    "    sf.write(folder / f\"to_play-{filename}.wav\", output[\"waveform\"], 22050, \"PCM_24\")\n",
    "\n",
    "def play_only_synthesis(device, model, vocoder, denoiser, text, spk, language):\n",
    "    text = text.strip()\n",
    "    text_processed = process_text(text, device, language)\n",
    "\n",
    "    output = model.synthesise(\n",
    "        text_processed[\"x\"],\n",
    "        text_processed[\"x_lengths\"],\n",
    "        n_timesteps=STEPS,\n",
    "        temperature=TTS_TEMPERATURE,\n",
    "        spks=spk,\n",
    "        length_scale=SPEAKING_RATE,\n",
    "    )\n",
    "    output[\"waveform\"] = to_waveform(output[\"mel\"], vocoder, denoiser)\n",
    "\n",
    "    output[\"waveform\"] = np.clip(output[\"waveform\"], -1.0, 1.0)\n",
    "\n",
    "    save_to_folder(i, output, WAV_PATH)\n",
    "\n",
    "def assert_required_models_available():\n",
    "    save_dir = get_user_data_dir()\n",
    "    model_path = TTS_MODEL_PATH\n",
    "\n",
    "    vocoder_path = save_dir / f\"{VOCODER_NAME}\"\n",
    "    assert_model_downloaded(vocoder_path, VOCODER_URLS[VOCODER_NAME])\n",
    "    return {\"matcha\": model_path, \"vocoder\": vocoder_path}\n",
    "\n",
    "def contains_only_non_emoji(string):\n",
    "    return all(not emoji.is_emoji(char) for char in string) and len(string.strip()) > 0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    tts_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    #tts_device = \"cpu\"\n",
    "    paths = assert_required_models_available()\n",
    "\n",
    "    save_dir = get_user_data_dir()\n",
    " \n",
    "    tts_model = load_matcha(paths[\"matcha\"], tts_device)\n",
    "    vocoder, denoiser = load_vocoder(VOCODER_NAME, paths[\"vocoder\"], tts_device)\n",
    "\n",
    "    with open(SCRIPT_PATH, 'r') as file:\n",
    "        for i, line in enumerate(file):\n",
    "            # Strip any extra whitespace (like newlines)\n",
    "            clean_line = line.strip()\n",
    "            if VOICE == 'emoji':\n",
    "                spk = torch.tensor([12], device=tts_device, dtype=torch.long)\n",
    "                for emote in emoji_mapping:\n",
    "                    if emote in clean_line:\n",
    "                        spk = torch.tensor([emoji_mapping[emote]], device=tts_device, dtype=torch.long)\n",
    "                        break\n",
    "            elif VOICE == 'base':\n",
    "                spk = torch.tensor([1], device=tts_device, dtype=torch.long)\n",
    "            elif VOICE == 'default':\n",
    "                spk = torch.tensor([12], device=tts_device, dtype=torch.long)\n",
    "            else:\n",
    "                print(\"hmmm wrong voice\")\n",
    "            clean_line = emoji.replace_emoji(clean_line, '')\n",
    "            #matcha cannot handle brackets\n",
    "            clean_line = clean_line.replace(')', '')\n",
    "            clean_line = clean_line.replace('(', '')\n",
    "            play_only_synthesis(tts_device, tts_model, vocoder, denoiser, clean_line, spk, LANGUAGE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feel-me",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
